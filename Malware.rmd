---
title: "**HarvardX Data Science Professional Certificate  \n  PH125.9x Capstone 2 - Malware Detection**"
author: "_Hugo Aquino_"
date: "_`r Sys.Date()`_"
urlcolor: blue
geometry: margin=0.57in
output:
  rmarkdown::pdf_document:
    toc: true
    toc_depth: 4
    number_sections: yes
    fig_caption: yes
    highlight: tango
    keep_tex: yes
    includes:
      in_header: header.tex
header-includes:
  - \usepackage{titling}
  - \usepackage{fancyhdr}
  - \pretitle{\begin{center}
    \includegraphics[width=3in,height=3in]{edx_logo.png}\LARGE\\}
  - \posttitle{\end{center}}

include-before: '`\newpage{}`{=latex}'
---

`\newpage{}`{=latex}'

\addtolength{\headheight}{0.35cm} 
\pagestyle{fancyplain} 
\lhead{\includegraphics[height=1cm]{edx_logo.png}} 
\rhead{\includegraphics[height=1.5cm]{hardvard_x.jpeg}} 
\renewcommand{\headrulewidth}{0pt}

# Introduction 

**Data** is the _new fuel_ of this era in which many situations can be tracked using records that came from several sources. These data need to be cleaned and organized in a way that with the support of tools such as **R** and techniques such as **machine learning**, the data can talk to show patterns and relationships that allow us to anticipate and therefore take better decisions or protect digital assets.

**Data Science** is emerging as one of the most important knowledge areas and the **data scientists** are becoming one of the best jobs paid, this role combines computing/programming skills with statistics to analyze raw data and transforming it for its use on an industry. This knowledge area is spreading to be used in areas such as **Cybersecurity**.

According to [Cisco][cisco], [malware][malware] is a contraction for **"malicious sofware"** which is any intrusive software developed by **cybercriminals** or **hackers** to steal data and damage or destroy computers and computer systems. Examples of common malware include: _viruses, worms, Trojan viruses, spyware, adware_ and _ransomware_.

On **2009, 12.4 million** malware infections were reported, by **2018** the attacks were **812.67 million**. In **2020**, **61%** of organizations experienced malware activity that spread from one employee to another. In **2021** [Mimecast][mimecast] found that **61%** of organizations experienced a ransomware attack that led to at least a partial disruption of business operations.

The global cybercrime damage costs are: **6 Trillion USD a year**, **500 Billion USD by month**, **115.4 Billion USD by week**, **16.4 Billion USD by day**, **684.9 Million USD by hour**, **11.4 Million USD by minute** and **190,000 by second**.

Therefore and as a way to continue acquiring the skills needed to become a data scientist, this project will be focused on the evaluation of **four classification algorithms** to determine if a file is a **malware** or **not** using a dataset found on [Kaggle][kaggle_dataset] called **Malware Analysis Dataset** of files that run **Microsoft Windows** as operating system. 

In order to compare the different algorithms, these parameters will be evaluated:

* **Accuracy**, **Sensitivity** and **Specificity** with the highest value obtained.
* **FPR** with the lowest value obtained.

The files required for this project ([pdf][pdf_file], [rmd][rmd_file], [R][r_file]) are hosted on [github][github].

`\newpage{}`{=latex}'

# Methods

## Libraries

The libraries used for this project are:

```{r loading-libraries, warning = FALSE, message = FALSE}

if(!require(tidyverse)) install.packages(
  "tidyverse", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(devtools)) install.packages(
  "devtools", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(readr)) install.packages(
  "readr", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(data.table)) install.packages(
  "data.table", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(rvest)) install.packages(
  "rvest", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(caret)) install.packages(
  "caret", repos = "http://cran.us.r-project.org",dependencies = TRUE)
if(!require(kableExtra)) install.packages(
  "kableExtra", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(corrr)) install.packages(
  "corrr", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(knitr)) install.packages(
  "knitr", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(e1071)) install.packages(
  "e1071", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(class)) install.packages(
  "class", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(tree)) install.packages(
  "tree", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(ISLR)) install.packages(
  "ISLR", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(randomForest)) install.packages(
  "randomForest", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(scales)) install.packages(
  "scales", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(ggplot2)) install.packages(
  "ggplot2", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(ggthemes)) install.packages(
  "ggthemes", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(rpart)) install.packages(
  "rpart", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(rpart.plot)) install.packages(
  "rpart.plot", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(gclus)) install.packages(
  "gclus", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(corrplot)) install.packages(
  "corrplot", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(ROCR)) install.packages(
  "ROCR", repos = "http://cran.us.r-project.org", dependencies = TRUE)
if(!require(tictoc)) install.packages(
  "tictoc", repos = "http://cran.us.r-project.org", dependencies = TRUE)

# Load libraries
library(tidyverse)
library(devtools)
library(readr)
library(data.table)
library(rvest)
library(caret)
library(kableExtra)
library(corrr)
library(knitr)
library(e1071)
library(class)
library(tree)
library(ISLR)
library(randomForest)
library(scales)
library(ggplot2)
library(ggthemes)
library(rpart)
library(rpart.plot)
library(corrplot)
library(ROCR)
library(tictoc)

```

```{r functions and configurations, include=FALSE}

# Knit options
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.align="center", 
                      out.width="70%")

# Multiplot function
# Code copied from 
# https://stackoverflow.com/questions/24387376/r-error-could-not-find-function-multiplot-using-cookbook-example
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

```

`\newpage{}`{=latex}'

```{r web-scrapping, include=FALSE}

# This is URL of the site
url <- paste0("https://docs.microsoft.com/en-us/windows/win32/debug/pe-format")

# Read the page on HTML
page_loaded_html <- read_html(url)

# The class of this object
class(page_loaded_html)

# Convert HTML tables into data frames
tables <- page_loaded_html %>% html_nodes("table")

# Interested on table 2 - COFF file header
coff_file_header <- tables[[2]] %>% html_table

# Interested on table 3 - Machine Types
machines_types <- tables[[3]] %>% html_table
# Eliminate the first column named as "Constant"
machines_types <- subset( machines_types, select = -Constant)

# Interested on table 4 - Characteristics
characteristics <- tables[[4]] %>% html_table
characteristics <- subset( characteristics, select = -Flag)

# Interested on table 7 - Optional Header Standard Fields
optional_header_standard_fields <- tables[[7]] %>% html_table

# Interested on table 8 - PE32 additional field
pe32_additional_field <- tables[[8]] %>% html_table

# Interested on table 9 - Optional header windows specific fields
optional_header_windows_specific_fields <- tables[[9]] %>% html_table

# Interested on table 10 - Windows Subsystem
windows_subsystem_fields <- tables[[10]] %>% html_table
# Eliminate the first column named as "Constant"
windows_subsystem_fields <- subset(windows_subsystem_fields, select = -Constant)

# Interested on table 11 - DLL Characteristics
dll_characteristics_fields <- tables[[11]] %>% html_table
```

## Data extraction

A dataset was found on [Kaggle][kaggle_dataset] called **Malware Analysis Dataset** that contains records of files running **Microsoft Windows** as operating system are used on this project and for download the dataset, the **Kaggle API** must be used. 

```{r dataset extraction using Kaggle API, include=FALSE}

# Download file
# During the day kaggle.com is with high load that maybe this 
# error would be generated in this section:
# In download.file(response[["url"]], "archive.zip", mode = "wb") :
# InternetOpenUrl failed: 'The operation timed out'
# Error in download.file(response[["url"]], "archive.zip", mode = "wb") 
# Try to execute at other moment of the day

if (file.exists("./data.csv") == TRUE){
  # Read file using "|" as delimiter and "." as decimal points
  data_loaded <- read.delim("data.csv", header = TRUE, sep = "|", dec = ".")
} else {
  # R - Kaggler - API integration
  # The steps appear on this URL             
  # https://medium.com/mcd-unison/how-to-use-kaggle-api-to-download-datasets-in-r-312179c7a99c
  # Load Kaggler R API repository
  devtools::install_github("ldurazo/kaggler")
  
  # Load library
  library(kaggler)
  
  # Authenticate with the token generated
  # If you would like to do automatically, you will have 
  # to create your token con kaggle.com and put on the directory
  # where you want to run this file. 
  # For security reasons the token of the creator of this code
  # will not be uploaded to github.com
  kgl_auth(creds_file = 'kaggle.json')
  
  # Get the response from kaggle
  response <- kgl_datasets_download_all(
    owner_dataset = "divg07/malware-analysis-dataset")
  
  # Download file
  download.file(response[["url"]], "archive.zip", mode="wb")
  
  # Unzip file
  unzip_result <- unzip("archive.zip", overwrite = TRUE)
  }

```
![Malware Analysis Dataset used from Kaggle.com](malware_analysis_dataset.png)

The file originally has to be decompressed and parsed using **"|"** as delimiter and **"."** as decimal points.

![Raw data](data.png)

`\newpage{}`{=latex}'

## PE (Portable Executable) file

The structure of a **Windows** [PE file][PE_format] is displayed in the next figure. 

**PE format** is a **data structure** that tells Windows Operating System loader what information is required to manage the wrapped executable code. These **PE data structures** include:

* **DOS Header**
* **DOS Stub**
* **PE File Header**
* **Image Optional Header**
* **Section Table**
* **Data Dictionaries**
* **Sections**

On **Appendix A** a detailed explanation of the fields is provided.

![PE file structure](Portable_Executable_32_bit_Structure.png)

## About data_loaded dataset

The dataset was named as **data_loaded** and is of the type **`r class(data_loaded)`**. This dataset has **`r format(nrow(data_loaded),big.mark=",")`** observations and **`r ncol(data_loaded)`** columns. Additionally these observations are records of processes running on a information technology infrastructure (server, desktop, laptop, tablet) using **Windows** as operating system. Technically these observations belongs to a **PE (Portable Executable)** file respectively.

The column **legitimate** is very important because its value indicate if the program is **valid** (value **"1"**) or not (**malware**, value **"0"**), the next table shows the amount of records, and for this project this variable will be our **predictor**.

```{r legitimate-field-analysis, warning = FALSE, message = TRUE}

# Display amount of records that are malware or not
tribble(
  ~"Type", ~"# records",
  "Malware", data_loaded %>% filter(legitimate == 0) %>% nrow(),
  "Not malware", data_loaded %>% filter(legitimate == 1) %>% nrow(),
  "Total", data_loaded %>% nrow()
) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Amount of records on the dataset",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T)

```

The **entropy** for a malware and not malware program is displayed in the following histogram. The range of values a file’s entropy must come in as per **Shanon’s algorithm** is **0 to 8**. So, when its value is zero, one can say the outcome is certain. On contrary, when its value is 8, the outcome is most unpredictable it could be.

```{r entropy-histograms, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Files´ entropy"}

entropy_malware <- data_loaded %>% filter(legitimate == 0) %>% summarise(mean(SectionsMaxEntropy))
entropy_not_malware <- data_loaded %>% filter(legitimate == 1) %>% summarise(mean(SectionsMaxEntropy))

malware_histogram_entropy <- data_loaded %>% filter(legitimate == 0) %>% 
  ggplot(aes(x=SectionsMaxEntropy)) + 
  geom_histogram(bins=10, col="black", fill="red", alpha = .2) + 
  scale_y_continuous(labels=comma) +
  geom_vline(
    xintercept = entropy_malware$`mean(SectionsMaxEntropy)`, 
    col = "red", 
    linetype = "dashed") +
  annotate(
    "text",
    x = 6.4,
    y = 65000,
    label = "mean entropy: 7.38", 
    color = "red", size = 3) +
  labs(
    x="Entropy", 
    y="# Files", caption = "source data: data_loaded") +
  theme_hc() + ggtitle("Files with Malware") 
  
not_malware_histogram_entropy <- data_loaded %>% filter(legitimate == 1) %>% 
  ggplot(aes(x=SectionsMaxEntropy)) + 
  geom_histogram(bins=10, col="blue", fill="green", alpha = .2) + 
  scale_y_continuous(labels=comma) +
  geom_vline(
    xintercept = entropy_not_malware$`mean(SectionsMaxEntropy)`, 
    col = "red", 
    linetype = "dashed") +
  annotate(
    "text",
    x = 5.1,
    y = 23000,
    label = "mean entropy: 5.96", 
    color = "red", size = 3) +
  labs(
    x="Entropy", 
    y="# Files", caption = "source data: data_loaded") +
  theme_hc() + ggtitle("Files without Malware") 

multiplot(not_malware_histogram_entropy,
          malware_histogram_entropy,
          cols = 2)

```

Now a correlation analysis between the variables will be done against the predictor (legitimate), being the results displayed in the following table

```{r correlation-analysis, warning = FALSE, message = FALSE}

# Create a dataset called "data_analysis_correlation 
# excluding the "Name" and "md5" columns from "data_loaded" dataset

data_analysis_correlation <- subset(data_loaded,select = -Name)
data_analysis_correlation <- subset(data_analysis_correlation,select = -md5)

# Create a correlation matrix 
data_correlated <- correlate(data_analysis_correlation)

# Focus the correlation based on "legitimate" 
data_correlated_focused_legitimate <- data_correlated %>% focus(legitimate) %>% arrange(desc(legitimate))
```

```{r correlation-table, warning = FALSE, message = TRUE}

# Display the correlation factors
data_correlated_focused_legitimate %>% kbl(., 
                     booktabs = T, 
                     longtable = T,
                     caption = "Correlations focused on \"legitimate\" field") %>% 
  kable_styling(latex_options = c("HOLD_position","repeat_header")) %>%
  row_spec(0, bold = T) %>% 
  column_spec(
    2, 
    color = "white",
    background = spec_color(
      data_correlated_focused_legitimate$legitimate, 
      direction= 1,
      end= max(data_correlated_focused_legitimate$legitimate)),
    popover = paste("legitimate:", data_correlated_focused_legitimate$legitimate))

```

The next table summarize the information about how many variables correspond to a correlation factor. For the rest of this project the correlation factor to be used will be **0.10**.

```{r correlation-fields, warning = FALSE, message = TRUE}

# Display amount of variables and names based on a correlation factor 
tribble(
  ~"Correlation factor", ~"# variables", ~"Variables´ name",
  "Up 0", data_correlated_focused_legitimate %>% filter(legitimate > 0) %>% nrow(), data_correlated_focused_legitimate %>% filter(legitimate > 0) %>% .$term,
  "Below 0", data_correlated_focused_legitimate %>% filter(legitimate < 0) %>% nrow(), data_correlated_focused_legitimate %>% filter(legitimate < 0) %>% .$term,
  "Up 0.10", data_correlated_focused_legitimate %>% filter(legitimate > 0.10) %>% nrow(), data_correlated_focused_legitimate %>% filter(legitimate > 0.10) %>% .$term,) %>%
  kbl(
    ., 
    booktabs = T, 
    caption = "Amount of variables based on a correlation factor",
    format.args = list(big.mark = ","),
    digits = c(3, 4)) %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T) %>% column_spec(3, width = "30em")

```

## About data_filtrated dataset

```{r data_filtrated_dataset, warning = FALSE, message = FALSE}

# Create a dataset to store the names of the variables that are up the correlation factor selected
variables_to_be_included <- data_correlated_focused_legitimate %>% filter(legitimate > 0.10) %>% .$term

# Add the "legitimate" variable
variables_to_be_included[length(variables_to_be_included) +1 ] <- "legitimate"

# Create another dataset with only the information related to the variables selected
data_filtrated <- subset(data_loaded,select = variables_to_be_included)
```

A new dataset **data_filtrated** will be created with variables which correlation factor are bigger than **0.10**.

This dataset is of the type **`r class(data_filtrated)`**, which  has **`r format(nrow(data_filtrated),big.mark=",")`** observations and **`r ncol(data_filtrated)`** columns.

A graph of the variables sorted based on correlation is the following.

![Sorted colored variables by correlation](correlation_sorted_colored_variables.jpg)

Also a correlation map of these variables is generated

```{r correlation-map, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Correlation map"}

# Create a correlation plot
numeric_var <- names(data_filtrated)[which(sapply(data_filtrated, is.numeric))]

data_filtrated_cont <- data_filtrated[numeric_var]

correlations <- cor(na.omit(data_filtrated_cont[,]))

corrplot(correlations,
         method="square", 
         type='lower', 
         tl.offset=0.4,
         tl.cex=0.8,
         diag=FALSE)

```

### About `r variables_to_be_included[1]`

Based on the **`r variables_to_be_included[1]`** contained in the dataset the distribution is: 

```{r machine-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Kind of processors"}

data_filtrated_Machine <- data_filtrated %>% select(Machine,legitimate)
names(data_filtrated_Machine) <- c("Value","legitimate")
data_filtrated_Machine <- data_filtrated_Machine %>% left_join(machines_types,by="Value")

data_filtrated_Machine %>%
  group_by(Description) %>%
  summarize(processors=n()) %>%
  arrange(desc(processors)) %>%
  ggplot(aes(x=reorder(Description, processors), y=processors)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= processors), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title="Kind of processor" , 
       caption = "source data: data_loaded_filtrated")
```

The maximum amount of processors are **`r format(data_filtrated_Machine %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Machine %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) being of the type **"`r data_filtrated_Machine %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(Description)`"**.

```{r machine-graph-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Machine - Files with malware"}

data_filtrated_Machine %>%
  filter(legitimate == 0) %>% 
  group_by(Description) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(Description, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title="Kind of processor",
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")
```

The maximum amount of processors with files **with malware** are **`r format(data_filtrated_Machine %>% filter(legitimate == 0) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Machine %>% filter(legitimate == 0) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) being of the type **"`r data_filtrated_Machine %>% filter(legitimate == 0) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(Description)`"**.

```{r machine-graph-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Machine - Files without malware"}

data_filtrated_Machine %>%
  filter(legitimate == 1) %>% 
  group_by(Description) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(Description, Count), y=Count)) +
  geom_bar(stat='identity', fill="green") +
  coord_flip(y=c(0, 30000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title="Kind of processor",
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")
```

The maximum amount of processors with files **without malware** are **`r format(data_filtrated_Machine %>% filter(legitimate == 1) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors)%>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Machine %>% filter(legitimate == 1) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(processors) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) being of the type **"`r data_filtrated_Machine %>% filter(legitimate == 1) %>% group_by(Description) %>% summarize(processors=n()) %>% filter(processors == max(processors)) %>% select(Description)`"**.

### About `r variables_to_be_included[2]`

Based on the **`r variables_to_be_included[2]`** contained in the dataset the distribution is: 

```{r sizeofoptionalheader-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="SizeofOptionalHeader"}

data_filtrated_SizeOfOptionalHeader <- data_filtrated %>% select(SizeOfOptionalHeader,legitimate)

data_filtrated_SizeOfOptionalHeader %>%
  group_by(SizeOfOptionalHeader) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(SizeOfOptionalHeader, Count), y=Count)) +
  geom_bar(stat='identity', fill="green") +
  coord_flip(y=c(0, 125000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[2], 
       caption = "source data: data_loaded_filtrated")

```

The **`r variables_to_be_included[2]`** with the highest amount of files is **`r data_filtrated_SizeOfOptionalHeader %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(SizeOfOptionalHeader) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_SizeOfOptionalHeader %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_SizeOfOptionalHeader %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r sizeofoptionalheader-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Size of Optional Header - Files with and without Malware"}

SizeOfOptionalHeader_malware <- data_filtrated_SizeOfOptionalHeader %>%
  filter(legitimate == 0) %>% 
  group_by(SizeOfOptionalHeader) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(SizeOfOptionalHeader, Count), y=Count)) +
   geom_bar(stat='identity', fill="red") +
   coord_flip(y=c(0, 100000)) +
   labs(x= "", y="# files") + 
   geom_text(aes(label= Count), 
           position = position_stack(vjust= 0.5), 
           colour = "black", size = 4) +
   theme_hc() + 
  labs(title=variables_to_be_included[2],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

SizeOfOptionalHeader_not_malware <- data_filtrated_SizeOfOptionalHeader %>%
  filter(legitimate == 1) %>% 
  group_by(SizeOfOptionalHeader) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(SizeOfOptionalHeader, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 30000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[2],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(SizeOfOptionalHeader_not_malware,
          SizeOfOptionalHeader_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[2]`** with the highest amount is **`r data_filtrated_SizeOfOptionalHeader %>% filter(legitimate == 1) %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(SizeOfOptionalHeader) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_SizeOfOptionalHeader %>% group_by(SizeOfOptionalHeader) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_SizeOfOptionalHeader %>% filter(legitimate == 1) %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[2]`** with the highest amount is **`r data_filtrated_SizeOfOptionalHeader %>% filter(legitimate == 0) %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(SizeOfOptionalHeader) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_SizeOfOptionalHeader %>% group_by(SizeOfOptionalHeader) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_SizeOfOptionalHeader %>% filter(legitimate == 0) %>% group_by(SizeOfOptionalHeader) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[3]`

Based on the **`r variables_to_be_included[3]`** contained in the dataset the distribution is: 

```{r subsystem-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Subsystem"}

data_filtrated_Subsystem <- data_filtrated %>% select(Subsystem,legitimate)

data_filtrated_Subsystem %>%
  group_by(Subsystem) %>%
  summarize(subsystems=n()) %>%
  arrange(desc(subsystems)) %>%
  ggplot(aes(x=reorder(Subsystem, subsystems), y=subsystems)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 125000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= subsystems), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[3], 
       caption = "source data: data_loaded_filtrated")
```
The **`r variables_to_be_included[3]`** with the highest amount of files is **`r data_filtrated_Subsystem %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Subsystem) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Subsystem %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Subsystem %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r subsystem-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Subsystem - Files with and without Malware"}

windows_subsystem_field_malware <- data_filtrated_Subsystem %>% 
  filter(legitimate == 0) %>% 
  group_by(Subsystem) %>% 
  summarize(Count=n()) %>% 
  filter(Count == max(Count)) %>% 
  select(Subsystem) %>% as.numeric(.)

windows_subsystem_field_not_malware <- data_filtrated_Subsystem %>% 
  filter(legitimate == 1) %>% 
  group_by(Subsystem) %>% 
  summarize(Count=n()) %>% 
  filter(Count == max(Count)) %>% 
  select(Subsystem) %>% as.numeric(.)

Subsystem_malware <- data_filtrated_Subsystem %>%
  filter(legitimate == 0) %>% 
  group_by(Subsystem) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(Subsystem, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[3],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

Subsystem_not_malware <- data_filtrated_Subsystem %>%
  filter(legitimate == 1) %>% 
  group_by(Subsystem) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(Subsystem, Count), y=Count)) +
  geom_bar(stat='identity', fill="green") +
  coord_flip(y=c(0, 25000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[3],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(Subsystem_not_malware,
          Subsystem_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[3]`** with the highest amount is **`r data_filtrated_Subsystem %>% filter(legitimate == 1) %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Subsystem) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Subsystem %>% group_by(Subsystem) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Subsystem %>% filter(legitimate == 1) %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files. The description of the Windows subsystem required to run the image is **"`r windows_subsystem_fields %>% filter(Value == windows_subsystem_field_not_malware) %>% select(Description)`"**.

While files **with malware** the **`r variables_to_be_included[3]`** with the highest amount is **`r data_filtrated_Subsystem %>% filter(legitimate == 0) %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Subsystem) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Subsystem %>% group_by(Subsystem) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Subsystem %>% filter(legitimate == 0) %>% group_by(Subsystem) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files. The description of the Windows subsystem required to run the image is **"`r windows_subsystem_fields %>% filter(Value == windows_subsystem_field_malware) %>% select(Description)`"**.

### About `r variables_to_be_included[4]`

Based on the **`r variables_to_be_included[4]`** contained in the dataset the distribution is: 

```{r majorsubsystemversion-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="MajorSubsystemVersion"}

data_filtrated_MajorSubsystemVersion <- data_filtrated %>% select(MajorSubsystemVersion,legitimate)

data_filtrated_MajorSubsystemVersion %>%
  group_by(MajorSubsystemVersion) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(MajorSubsystemVersion, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 80000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[4], 
       caption = "source data: data_loaded_filtrated")
```
The **`r variables_to_be_included[4]`** with the highest amount of files is **`r data_filtrated_MajorSubsystemVersion %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(MajorSubsystemVersion) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_MajorSubsystemVersion %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_MajorSubsystemVersion %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r majorsubsystemversion-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="MajorSubsystemVersion - Files with and without Malware"}

MajorSubsystemVersion_malware <- data_filtrated_MajorSubsystemVersion %>%
  filter(legitimate == 0) %>% 
  group_by(MajorSubsystemVersion) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(MajorSubsystemVersion, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 70000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[4],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

MajorSubsystemVersion_not_malware <- data_filtrated_MajorSubsystemVersion %>%
  filter(legitimate == 1) %>% 
  group_by(MajorSubsystemVersion) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  ggplot(aes(x=reorder(MajorSubsystemVersion, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 20000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[4],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(MajorSubsystemVersion_not_malware,
          MajorSubsystemVersion_malware,
          cols=2)
```
For files **without malware** the **`r variables_to_be_included[4]`** with the highest amount is **`r data_filtrated_MajorSubsystemVersion %>% filter(legitimate == 1) %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(MajorSubsystemVersion) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_MajorSubsystemVersion %>% group_by(MajorSubsystemVersion) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_MajorSubsystemVersion %>% filter(legitimate == 1) %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[4]`** with the highest amount is **`r data_filtrated_MajorSubsystemVersion %>% filter(legitimate == 0) %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(MajorSubsystemVersion) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_MajorSubsystemVersion %>% group_by(MajorSubsystemVersion) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_MajorSubsystemVersion %>% filter(legitimate == 0) %>% group_by(MajorSubsystemVersion) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[5]`

Based on the **`r variables_to_be_included[5]`** contained in the dataset the distribution is: 

```{r versioninformationsize-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="VersionInformationSize"}

data_filtrated_VersionInformationSize <- data_filtrated %>% select(VersionInformationSize,legitimate)

data_filtrated_VersionInformationSize %>%
  group_by(VersionInformationSize) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(VersionInformationSize, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 40000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[5], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[5]`** with the highest amount of files is **`r data_filtrated_VersionInformationSize %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(VersionInformationSize) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_VersionInformationSize %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_VersionInformationSize %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r versioninformationsize-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="VersionInformationSize - Files with and without Malware"}

VersionInformationSize_malware <- data_filtrated_VersionInformationSize %>%
  filter(legitimate == 0) %>% 
  group_by(VersionInformationSize) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(VersionInformationSize, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 40000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[5],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

VersionInformationSize_not_malware <- data_filtrated_VersionInformationSize %>%
  filter(legitimate == 1) %>% 
  group_by(VersionInformationSize) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(VersionInformationSize, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 30000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[5],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(VersionInformationSize_not_malware,
          VersionInformationSize_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[5]`** with the highest amount is **`r data_filtrated_VersionInformationSize %>% filter(legitimate == 1) %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(VersionInformationSize) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_VersionInformationSize %>% group_by(VersionInformationSize) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_VersionInformationSize %>% filter(legitimate == 1) %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[5]`** with the highest amount is **`r data_filtrated_VersionInformationSize %>% filter(legitimate == 0) %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(VersionInformationSize) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_VersionInformationSize %>% group_by(VersionInformationSize) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_VersionInformationSize %>% filter(legitimate == 0) %>% group_by(VersionInformationSize) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[6]`

Based on the **`r variables_to_be_included[6]`** contained in the dataset the distribution is: 

```{r resourceminentropy-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ResourcesMinEntropy - Files with and without Malware"}

data_filtrated_ResourcesMinEntropy <- data_filtrated %>% select(ResourcesMinEntropy,legitimate)

ResourcesMinEntropy_malware <- data_filtrated_ResourcesMinEntropy %>% filter(legitimate == 0) %>% 
  ggplot(aes(x=ResourcesMinEntropy)) + 
  geom_histogram(bins=8, col="black", fill="red", alpha = .2) + 
  scale_y_continuous(labels=comma) +
  labs(
    x=variables_to_be_included[6], 
    y="# Files", caption = "source data: data_loaded_filtrated") +
  theme_hc() + ggtitle("Files with Malware") 

ResourcesMinEntropy_not_malware <- data_filtrated_ResourcesMinEntropy %>% filter(legitimate == 1) %>% 
  ggplot(aes(x=ResourcesMinEntropy)) + 
  geom_histogram(bins=6, col="blue", fill="green", alpha = .2) + 
  scale_y_continuous(labels=comma) +
  labs(
    x=variables_to_be_included[6], 
    y="# Files", caption = "source data: data_loaded_filtrated") +
  theme_hc() + ggtitle("Files without Malware") 

multiplot(ResourcesMinEntropy_not_malware,
          ResourcesMinEntropy_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[6]`** according to the histogram with the highest number of files is between **2.5 to 3.5**. While files **with malware** the **`r variables_to_be_included[6]`** according to the histogram with the highest number of files is around **2.5**.

### About `r variables_to_be_included[7]`

Based on the **`r variables_to_be_included[7]`** contained in the dataset the distribution is: 

```{r characteristics-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Characteristics"}

data_filtrated_Characteristics <- data_filtrated %>% select(Characteristics,legitimate)

data_filtrated_Characteristics %>%
  group_by(Characteristics) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(Characteristics, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 70000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[7], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[7]`** with the highest amount of files is **`r data_filtrated_Characteristics %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Characteristics) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Characteristics %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Characteristics %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r characteristics-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Characteristics - Files with and without Malware"}

Characteristics_malware <- data_filtrated_Characteristics %>%
  filter(legitimate == 0) %>% 
  group_by(Characteristics) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(Characteristics, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 68000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[7],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

Characteristics_not_malware <- data_filtrated_Characteristics %>%
  filter(legitimate == 1) %>% 
  group_by(Characteristics) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(Characteristics, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 16000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[7],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(Characteristics_not_malware,
          Characteristics_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[7]`** with the highest amount is **`r data_filtrated_Characteristics %>% filter(legitimate == 1) %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Characteristics) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Characteristics %>% group_by(Characteristics) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Characteristics %>% filter(legitimate == 1) %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files. The description of the **`r variables_to_be_included[7]`** that contains flags that indicate attributes of the object or image file is **"`r characteristics$Description[14]`"**.

While files **with malware** the **`r variables_to_be_included[7]`** with the highest amount is **`r data_filtrated_Characteristics %>% filter(legitimate == 0) %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Characteristics) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_Characteristics %>% group_by(Characteristics) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_Characteristics %>% filter(legitimate == 0) %>% group_by(Characteristics) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files. The description of the **`r variables_to_be_included[7]`** is **"`r characteristics$Description[9]`"**.

### About `r variables_to_be_included[8]`

Based on the **`r variables_to_be_included[8]`** contained in the dataset the distribution is: 

```{r exportnb-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ExportNb"}

data_filtrated_ExportNb <- data_filtrated %>% select(ExportNb,legitimate)

data_filtrated_ExportNb %>%
  group_by(ExportNb) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ExportNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 110000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[8], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[8]`** with the highest amount of files is **`r data_filtrated_ExportNb %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ExportNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ExportNb %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ExportNb %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r exportnb-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ExportNb - Files with and without Malware"}

ExportNb_malware <- data_filtrated_ExportNb %>%
  filter(legitimate == 0) %>% 
  group_by(ExportNb) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ExportNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[8],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

ExportNb_not_malware <- data_filtrated_ExportNb %>%
  filter(legitimate == 1) %>% 
  group_by(ExportNb) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ExportNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 15000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[8],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(ExportNb_not_malware,
          ExportNb_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[8]`** with the highest amount is **`r data_filtrated_ExportNb %>% filter(legitimate == 1) %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ExportNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ExportNb %>% group_by(ExportNb) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ExportNb %>% filter(legitimate == 1) %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[8]`** with the highest amount is **`r data_filtrated_ExportNb %>% filter(legitimate == 0) %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ExportNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ExportNb %>% group_by(ExportNb) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ExportNb %>% filter(legitimate == 0) %>% group_by(ExportNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[9]`

Based on the **`r variables_to_be_included[9]`** contained in the dataset the distribution is: 

```{r importsnbordinal-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ImportsNbOrdinal"}

data_filtrated_ImportsNbOrdinal <- data_filtrated %>% select(ImportsNbOrdinal,legitimate)

data_filtrated_ImportsNbOrdinal %>%
  group_by(ImportsNbOrdinal) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ImportsNbOrdinal, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[9], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[9]`** with the highest amount of files is **`r data_filtrated_ImportsNbOrdinal %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNbOrdinal) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNbOrdinal %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNbOrdinal %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r importsnbordinal-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ImportsNbOrdinal - Files with and without Malware"}

ImportsNbOrdinal_malware <- data_filtrated_ImportsNbOrdinal %>%
  filter(legitimate == 0) %>% 
  group_by(ImportsNbOrdinal) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ImportsNbOrdinal, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 70000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[9],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

ImportsNbOrdinal_not_malware <- data_filtrated_ImportsNbOrdinal %>%
  filter(legitimate == 1) %>% 
  group_by(ImportsNbOrdinal) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ImportsNbOrdinal, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 30000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[9],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(ImportsNbOrdinal_not_malware,
          ImportsNbOrdinal_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[9]`** with the highest amount is **`r data_filtrated_ImportsNbOrdinal %>% filter(legitimate == 1) %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNbOrdinal) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNbOrdinal %>% group_by(ImportsNbOrdinal) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNbOrdinal %>% filter(legitimate == 1) %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[9]`** with the highest amount is **`r data_filtrated_ImportsNbOrdinal %>% filter(legitimate == 0) %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNbOrdinal) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNbOrdinal %>% group_by(ImportsNbOrdinal) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNbOrdinal %>% filter(legitimate == 0) %>% group_by(ImportsNbOrdinal) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[10]`

Based on the **`r variables_to_be_included[10]`** contained in the dataset the distribution is: 

```{r filealignment-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="FileAlignment"}

data_filtrated_FileAlignment <- data_filtrated %>% select(FileAlignment,legitimate)

data_filtrated_FileAlignment %>%
  group_by(FileAlignment) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(FileAlignment, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 150000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[10], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[10]`** with the highest amount of files is **`r data_filtrated_FileAlignment %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(FileAlignment) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_FileAlignment %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_FileAlignment %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r filealignment-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="FileAlignment - Files with and without Malware"}

FileAlignment_malware <- data_filtrated_FileAlignment %>%
  filter(legitimate == 0) %>% 
  group_by(FileAlignment) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(FileAlignment, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 100000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[10],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

FileAlignment_not_malware <- data_filtrated_FileAlignment %>%
  filter(legitimate == 1) %>% 
  group_by(FileAlignment) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(FileAlignment, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 40000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[10],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(FileAlignment_not_malware,
          FileAlignment_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[10]`** with the highest amount is **`r data_filtrated_FileAlignment %>% filter(legitimate == 1) %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(FileAlignment) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_FileAlignment %>% group_by(FileAlignment) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_FileAlignment %>% filter(legitimate == 1) %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[10]`** with the highest amount is **`r data_filtrated_FileAlignment %>% filter(legitimate == 0) %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(FileAlignment) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_FileAlignment %>% group_by(FileAlignment) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_FileAlignment %>% filter(legitimate == 0) %>% group_by(FileAlignment) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

### About `r variables_to_be_included[11]`

Based on the **`r variables_to_be_included[11]`** contained in the dataset the distribution is: 

```{r importsnb-graph, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ImportsNb"}

data_filtrated_ImportsNb <- data_filtrated %>% select(ImportsNb,legitimate)

data_filtrated_ImportsNb %>%
  group_by(ImportsNb) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(8) %>%
  ggplot(aes(x=reorder(ImportsNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 15000)) +
  labs(x= "", y="# files") +
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[11], 
       caption = "source data: data_loaded_filtrated")

```
The **`r variables_to_be_included[11]`** with the highest amount of files is **`r data_filtrated_ImportsNb %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNb %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNb %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

```{r importsnb-graph-malware-not-malware, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ImportsNb - Files with and without Malware"}

ImportsNb_malware <- data_filtrated_ImportsNb %>%
  filter(legitimate == 0) %>% 
  group_by(ImportsNb) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ImportsNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="red") +
  coord_flip(y=c(0, 15000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[11],
       subtitle="Files with Malware",
       caption = "source data: data_loaded_filtrated")

ImportsNb_not_malware <- data_filtrated_ImportsNb %>%
  filter(legitimate == 1) %>% 
  group_by(ImportsNb) %>% 
  summarize(Count=n()) %>% 
  arrange(desc(Count)) %>%
  head(6) %>%
  ggplot(aes(x=reorder(ImportsNb, Count), y=Count)) +
  geom_bar(stat='identity', fill="blue") +
  coord_flip(y=c(0, 10000)) +
  labs(x= "", y="# files") + 
  geom_text(aes(label= Count), 
            position = position_stack(vjust= 0.5), 
            colour = "black", size = 4) +
  theme_hc() + 
  labs(title=variables_to_be_included[11],
       subtitle="Files without Malware",
       caption = "source data: data_loaded_filtrated")

multiplot(ImportsNb_not_malware,
          ImportsNb_malware,
          cols=2)

```
For files **without malware** the **`r variables_to_be_included[11]`** with the highest amount is **`r data_filtrated_ImportsNb %>% filter(legitimate == 1) %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNb %>% group_by(ImportsNb) %>% filter(legitimate == 1) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNb %>% filter(legitimate == 1) %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

While files **with malware** the **`r variables_to_be_included[11]`** with the highest amount is **`r data_filtrated_ImportsNb %>% filter(legitimate == 0) %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(ImportsNb) %>% as.numeric(.)`** with a total of **`r format(data_filtrated_ImportsNb %>% group_by(ImportsNb) %>% filter(legitimate == 0) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.), big.mark=",")`** (**`r percent(data_filtrated_ImportsNb %>% filter(legitimate == 0) %>% group_by(ImportsNb) %>% summarize(Count=n()) %>% filter(Count == max(Count)) %>% select(Count) %>% as.numeric(.) / nrow(data_filtrated), accuracy = 0.01)`** of the records on the dataset) files.

## About train and test datasets

```{r train-test-set, warning = FALSE, message = FALSE}
# Use seed to replicate results
set.seed(2022, sample.kind="Rounding") # if using R 3.5 or earlier, use `set.seed(2022)`

# Validation set will be 10% of data_filtrated data
test_index <- createDataPartition(y = data_filtrated$legitimate, times = 1, p = 0.1, list = FALSE)

# Create the datasets
test_set <- data_filtrated[test_index,]
train_set <- data_filtrated[-test_index,]
```

**data_filtrated** dataset is splitted on another 2 datasets:

* **train_set** contains **`r format(nrow(train_set), big.mark=",")`** observations that will be used with every algorithm.
* **test_set** contains **`r format(nrow(test_set), big.mark=",")`** observations that will be used at the moment to obtain the respective **confusion matrix**.

`\newpage{}`{=latex}'

# Results

```{r prepare-datasets-algorithms, warning = FALSE, message = FALSE}
# Store in a dataset the value of "legitimate" variable for test and train datasets
test_set_legitimate <- test_set$legitimate
train_set_legitimate <- train_set$legitimate

# Create two additional datasets as a copy of test and train that will be used on decision tree
test_set_tree <- test_set
train_set_tree <- train_set

# Change "legitimate" variable to be a factor in the datasets that will be used on decision tree
test_set_tree$legitimate <- factor(test_set_tree$legitimate, levels = c(0, 1))
train_set_tree$legitimate <- factor(train_set_tree$legitimate, levels = c(0, 1))

# Apply scale featuring to the test and train datasets due to the different values in each variable
test_set <- scale(test_set[1:ncol(test_set)])
train_set <- scale(train_set[1:ncol(train_set)])

# Change the test and train datasets to be a data frame
test_set <- as.data.frame(test_set)
train_set <- as.data.frame(train_set)

# Restore the "legitimate" value on the test and train datasets
test_set$legitimate <- test_set_legitimate
train_set$legitimate <- train_set_legitimate

# Change "legitimate" variable to be a factor in the datasets that stored the "legitimate" value
train_set_legitimate <- factor(train_set_legitimate, levels = c(0, 1))
test_set_legitimate <- factor(test_set_legitimate, levels = c(0, 1))

# Change "legitimate" variable to be a factor in the test and train datasets
test_set$legitimate <- factor(test_set$legitimate, levels = c(0, 1))
train_set$legitimate <- factor(train_set$legitimate, levels = c(0, 1))
```

## About confusion matrix

For a **classification use case**, a **confusion matrix** or **error matrix** is used for summarizing the performance of a classification algorithm.

**Correct** and **incorrect** predictions are summarized in a table with their values and broken down by each class as is displayed in the next image.

The explanation of the key terms related to this performance tool are:

* **True Positive (TP)**: number of malicious PE files that classified as a malicious (malware).
* **True Negative(TN)**: number of benign PE files that classified as a benign (not malware).
* **False Positive (FP)**: number of benign PE files that classified as a malicious (malware).
* **False Negative (FN)**: number of malicious PE files that classified as a benign (not malware).
* **True Positive Rate (TPR) or Sensitivity**: ratio of malicious PE files that classified as a malicious to all the malicious (malware) files.
* **False Positive Rate (FPR)**: ratio of benign PE files that classified as a malicious to all the benign (not malware) files.
* **Accuracy**: ratio of correctly classified files to all files.
* **Specificity**: the proportion of negatives (not malware files) correctly identified as such (or true negative).

![Confusion Matrix](confusion_matrix.jpg)

The confusion matrix´s formulas are:

![Confusion Matrix Formulas](confusion_matrix_formulas.jpg)

## About ROC 

**ROC** stands for **Receiver Operating Characteristics**, and it is used to evaluate the prediction accuracy of a classifier model. ROC curve is a metric describing the trade-off between the sensitivity (true positive rate, TPR) and specificity (false positive rate, FPR) of a prediction in all probability cutoffs (thresholds). It can be used for binary and multi-class classification accuracy checking. 

## Algorithms

### First algorithm - Binary Logistic Regression

The **logistic model** (or **logit model**) is used to model the probability of a certain class or event existing such as **pass/fail**, **win/lose**, **alive/dead** or **healthy/sick**.

Logistic regression is an extension of linear regression that assures that the estimate of conditional probability $Pr(Y=1 | X=x)$ is between 0 and 1. This approach makes use of the logistic transformation: 

$$g(p)=\log\frac{1}{1-p}$$
With logistic regression, the conditional probability is:

$$g\{Pr(Y=1 | X=x)\}=\beta_{0}+\beta_{1}x$$
```{r binary-logistic-regression-algorithm, warning = FALSE, message = FALSE}

# Begin to obtain the time duration of the algorithm
tic("Total",quiet = TRUE)
tic("Apply algorithm",quiet = TRUE)

# Apply the algorithm
binary_logistic_regression_algorithm <- train_set %>% glm(legitimate ~ ., family=binomial, data=.)
toc(quiet = TRUE)

tic("Predict with the model",quiet = TRUE)
# Predict based on the algorithm
binary_logistic_regression_pred <- predict(binary_logistic_regression_algorithm, newdata = test_set, type = "response")
toc(quiet = TRUE)

# Calculate the time invested to run the algorithm
time_binary_logistic_regression_algorithm <- toc(quiet = TRUE)
time_binary_logistic_regression_algorithm <- time_binary_logistic_regression_algorithm$toc - time_binary_logistic_regression_algorithm$tic

# Create factors based on predictions
y_hat_binary_logistic_regression <- ifelse(binary_logistic_regression_pred > 0.5, "1", "0") %>% factor

# Elaborate the confusion matrix
binary_logistic_regression_confusion_matrix <- confusionMatrix(y_hat_binary_logistic_regression, test_set$legitimate)

# Performance
prediction_binary_logistic_regression <- prediction(binary_logistic_regression_pred, test_set$legitimate)
performance_binary_logistic_regression <- performance(prediction_binary_logistic_regression, "acc")

# Calculate AUC
auc_binary_logistic_regression <- performance(prediction_binary_logistic_regression, measure = "auc")

# Store the results on a dataframe
# Store the results on a dataframe
results <- data_frame(
  Algorithm = "#1 - Binary Logistic Regression",
  TP = binary_logistic_regression_confusion_matrix$table[1,1],
  TN = binary_logistic_regression_confusion_matrix$table[2,2],
  FP = binary_logistic_regression_confusion_matrix$table[2,1],
  FN = binary_logistic_regression_confusion_matrix$table[1,2],
  Accuracy = binary_logistic_regression_confusion_matrix$overall["Accuracy"],
  Sensitivity = binary_logistic_regression_confusion_matrix$byClass["Sensitivity"],
  FPR = 1 - binary_logistic_regression_confusion_matrix$byClass["Specificity"],
  Specificity = binary_logistic_regression_confusion_matrix$byClass["Specificity"],
  AUC = as.numeric(auc_binary_logistic_regression@y.values),
  Time = time_binary_logistic_regression_algorithm
)

```

The confusion matrix for this algorithm is:

```{r confusion-matrix-binary-logistic-regression, warning = FALSE, message = TRUE}
binary_logistic_regression_confusion_matrix$table
```

The performance of this algorithm is:

* **True Positive**: `r binary_logistic_regression_confusion_matrix$table[1,1]`
* **True Negative**: `r binary_logistic_regression_confusion_matrix$table[2,2]`
* **False Positive**: `r binary_logistic_regression_confusion_matrix$table[2,1]`
* **False Negative**: `r binary_logistic_regression_confusion_matrix$table[1,2]`
* **Accuracy**: `r binary_logistic_regression_confusion_matrix$overall["Accuracy"]`
* **True Positive Rate - Sensitivity**: `r binary_logistic_regression_confusion_matrix$byClass["Sensitivity"]`
* **False Positive Rate**: `r 1 - binary_logistic_regression_confusion_matrix$byClass["Specificity"]`
* **Specificity**: `r binary_logistic_regression_confusion_matrix$byClass["Specificity"]`
* **AUC**: `r auc_binary_logistic_regression@y.values`
* **Time to be executed**: `r time_binary_logistic_regression_algorithm` seconds

The ROC curve of this algorithm is

```{r roc-binary-logistic-regression, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ROC for Binary Logistic Regression"}

plot.new()
roc_binary_logistic_regression <- performance(prediction_binary_logistic_regression,"tpr","fpr")
plot(roc_binary_logistic_regression, colorize = T, lwd = 2)
abline(a = 0, b = 1) 
title(main = "ROC - Binary Logistic Regression")

```

### Second algorithm - Naive Bayes

**Naïve Bayes** is a conditional probability model, which given a problem instance to be classified, represented by a vector $x=(x_{1},...,x_{n})$ representing some n features (independent variables), it assigns to this instance probabilities

$$p(C_{k}|x_{1},...,x_{n})$$
for each of **K** possible outcomes or classes $C_{k}$. Using **Bayes' theorem**, the conditional probability can be decomposed as:

$$p(C_{k}|x)=\frac{p(C_{k}) \cdot p(x|C_{x})}{p(x)}$$
Other way to show this equation is:

$$p(x)=Pr(Y=1|X=x)=\frac{f_{X|Y=1} \cdot (X) \cdot Pr(Y=1)}{f_{X|Y=0} \cdot Pr(Y=0)+f_{X|Y=1} \cdot Pr(Y=1)}$$

```{r naive-bayes-regression-algorithm, warning = FALSE, message = FALSE}

# Obtain the time duration of the algorithm
tic("Total",quiet = TRUE)
tic("Apply algorithm",quiet = TRUE)

# Apply the algorithm
naiveBayes_algorithm <- naiveBayes(x = train_set[1:ncol(train_set)-1], y = train_set$legitimate)
toc(quiet = TRUE)

tic("Predict with the model",quiet = TRUE)
# Predict based on the algorithm
y_hat_naiveBayes <- predict(naiveBayes_algorithm, newdata = test_set)
toc(quiet = TRUE)

# Calculate the time invested to run the algorithm
time_naiveBayes <- toc(quiet = TRUE)
time_naiveBayes <- time_naiveBayes$toc - time_naiveBayes$tic

# Elaborate the confusion matrix
naiveBayes_confusion_matrix <- confusionMatrix(data=y_hat_naiveBayes, reference = test_set$legitimate)

# Performance
prediction_naiveBayes <- prediction(as.numeric(y_hat_naiveBayes)-1, test_set$legitimate)
performance_naiveBayes <- performance(prediction_naiveBayes, "acc")

# Calculate AUC
auc_naiveBayes <- performance(prediction_naiveBayes, measure = "auc")

# Append the results to the dataframe
results <- bind_rows(
  results,
  data_frame(
    Algorithm = "#2 - Naive Bayes",
    TP = naiveBayes_confusion_matrix$table[1,1],
    TN = naiveBayes_confusion_matrix$table[2,2],
    FP = naiveBayes_confusion_matrix$table[2,1],
    FN = naiveBayes_confusion_matrix$table[1,2],
    Accuracy = naiveBayes_confusion_matrix$overall["Accuracy"],
    Sensitivity = naiveBayes_confusion_matrix$byClass["Sensitivity"],
    FPR = 1 - naiveBayes_confusion_matrix$byClass["Specificity"],
    Specificity = naiveBayes_confusion_matrix$byClass["Specificity"],
    AUC = as.numeric(auc_naiveBayes@y.values),
    Time = time_naiveBayes)
)

```

The confusion matrix for this algorithm is:

```{r confusion-matrix-naive-bayes, warning = FALSE, message = TRUE}
naiveBayes_confusion_matrix$table
```

The performance of this algorithm is:

* **True Positive**: `r naiveBayes_confusion_matrix$table[1,1]`
* **True Negative**: `r naiveBayes_confusion_matrix$table[2,2]`
* **False Positive**: `r naiveBayes_confusion_matrix$table[2,1]`
* **False Negative**: `r naiveBayes_confusion_matrix$table[1,2]`
* **Accuracy**: `r naiveBayes_confusion_matrix$overall["Accuracy"]`
* **True Positive Rate - Sensitivity**: `r naiveBayes_confusion_matrix$byClass["Sensitivity"]`
* **False Positive Rate**: `r 1 - naiveBayes_confusion_matrix$byClass["Specificity"]`
* **Specificity**: `r naiveBayes_confusion_matrix$byClass["Specificity"]`
* **AUC**: `r as.numeric(auc_naiveBayes@y.values)`
* **Time to be executed**: `r time_naiveBayes` seconds

The ROC curve of this algorithm is

```{r roc-naivebayes, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ROC for naiveBayes"}

plot.new()
roc_naiveBayes <- performance(prediction_naiveBayes,"tpr","fpr")
plot(roc_naiveBayes, colorize = T, lwd = 2)
abline(a = 0, b = 1) 
title(main = "ROC - naiveBayes")

```

### Third algorithm - Decision Tree

A decision tree is a simple representation for classifying examples, its goal is to create a model that predicts the value of a target variable based on several input variables.

A tree is built by splitting the source set, constituting the root node of the tree, into subsets which constitute the successor children. The splitting is based on a set of splitting rules based on classification features. This process is repeated on each derived subset in a recursive manner called **recursive partitioning**. The recursion is completed when the subset at a node has all the same values of the target variable, or when splitting no longer adds value to the predictions.

```{r decision-tree-algorithm, warning = FALSE, message = FALSE}

# Begin to obtain the time duration of the algorithm
tic("Total",quiet = TRUE)
tic("Apply algorithm",quiet = TRUE)

# Apply the algorithm
tree_algorithm <- rpart(
  train_set_tree$legitimate ~ ., 
  data = train_set_tree[1:ncol(train_set_tree)-1])
toc(quiet = TRUE)

tic("Predict with the model",quiet = TRUE)
# Predict based on the algorithm
y_hat_tree <- predict(tree_algorithm, test_set_tree, type="class")
toc(quiet = TRUE)

# Calculate the time invested to run the algorithm
time_tree <- toc(quiet = TRUE)
time_tree <- time_tree$toc - time_tree$tic

# Elaborate the confusion matrix
tree_confusion_matrix <- confusionMatrix(data=y_hat_tree, reference = test_set_tree$legitimate)

# Performance
prediction_tree <- prediction(as.numeric(y_hat_tree)-1, test_set$legitimate)
performance_tree <- performance(prediction_tree, "acc")

# Calculate AUC
auc_tree <- performance(prediction_tree, measure = "auc")

```

For our case, this is tree created

```{r decision-tree-plot- algorithm, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="Decision Tree"}
# Plot the tree created
rpart.plot(tree_algorithm,
           type=3,
           under=TRUE,
           cex=0.7,
           under.cex=1.1,
           extra=100,
           box.palette = c("pink", "green"))

```

The confusion matrix for this algorithm is:

```{r confusion-matrix-decision-tree, warning = FALSE, message = TRUE}
tree_confusion_matrix$table

# Append the results to the dataframe
results <- bind_rows(
  results,
  data_frame(
    Algorithm = "#3 - Decision Tree",
    TP = tree_confusion_matrix$table[1,1],
    TN = tree_confusion_matrix$table[2,2],
    FP = tree_confusion_matrix$table[2,1],
    FN = tree_confusion_matrix$table[1,2],
    Accuracy = tree_confusion_matrix$overall["Accuracy"],
    Sensitivity = tree_confusion_matrix$byClass["Sensitivity"],
    FPR = 1 - tree_confusion_matrix$byClass["Specificity"],
    Specificity = tree_confusion_matrix$byClass["Specificity"],
    AUC = as.numeric(auc_tree@y.values),
    Time = time_tree)
)

```

The performance of this algorithm is:

* **True Positive**: `r tree_confusion_matrix$table[1,1]`
* **True Negative**: `r tree_confusion_matrix$table[2,2]`
* **False Positive**: `r tree_confusion_matrix$table[2,1]`
* **False Negative**: `r tree_confusion_matrix$table[1,2]`
* **Accuracy**: `r tree_confusion_matrix$overall["Accuracy"]`
* **True Positive Rate - Sensitivity**: `r tree_confusion_matrix$byClass["Sensitivity"]`
* **False Positive Rate**: `r 1 - tree_confusion_matrix$byClass["Specificity"]`
* **Specificity**: `r tree_confusion_matrix$byClass["Specificity"]`
* **AUC**: `r as.numeric(auc_tree@y.values)`
* **Time to be executed**: `r time_tree` seconds

The ROC curve of this algorithm is

```{r roc-tree, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ROC for Decision Tree"}

# Create a ROC curve
plot.new()
roc_tree <- performance(
  prediction_tree,
  "tpr",
  "fpr")
plot(roc_tree, colorize = T, lwd = 2)
abline(a = 0, b = 1) 
title(main = "ROC - Decision Tree")

```

### Fourth algorithm - Random Forest

**Random forest** or **random decision forest** is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. For classification tasks, the output of the random forest is the class selected by most trees.

**Bagging** is an abbreviation for **Bootstrapping Aggregating**. It is a technique that improves the stability and accuracy of regression and classification algorithms. The biggest advantages and reasons to use bagging are that it __reduces variance__ and helps in __avoiding overfitting__. Bagging is most commonly used for decision tree algorithms.

Given a training set $X=x_{1},x_{2},x_{3},...,x_{n}$ with responses $Y=y_{1},y_{2},y_{3},...,y_{n}$ random samples are taken from the training set multiple times and fit trees to them. Let $f(x_{i},y_{i})$ be the decision tree for the variables $x_{i}$ and $y_{i}$. 

To predict the results for $x^{´}$ the result can be averaged of all the trees $f_{i}$ corresponding to $x^{´}$ (in case of continous).

$$\hat f=\frac{1}{N}\cdot \sum_{i=1}^{N} f_{i}(x^\frown)$$

In the case of categorical output, the majority output can be chosen. An estimation of the uncertainty of the prediction can be calculated as:

$$\sigma=\sqrt \frac{\sum_{i=1}^{N} (f_{i}(x^\frown)-\hat f)}{N-1}$$

```{r random-forest-algorithm, warning = FALSE, message = FALSE}

# Begin to obtain the time duration of the algorithm
tic("Total",quiet = TRUE)
tic("Apply algorithm",quiet = TRUE)

# Apply the algorithm
random_forest_algorithm <- randomForest(
  train_set$legitimate ~ .,
  data = train_set[1:ncol(train_set)-1])
toc(quiet = TRUE)

tic("Predict with the model",quiet = TRUE)
# Predict based on the algorithm
y_hat_random_forest <- predict(random_forest_algorithm, newdata = test_set)
toc(quiet = TRUE)

# Calculate the time invested to run the algorithm
time_random_forest <- toc()
time_random_forest <- time_random_forest$toc - time_random_forest$tic

# Elaborate the confusion matrix
random_forest_confusion_matrix <- confusionMatrix(data=y_hat_random_forest, reference = test_set$legitimate)

# Performance
prediction_random_forest <- prediction(as.numeric(y_hat_random_forest)-1, test_set$legitimate)
performance_random_forest <- performance(prediction_random_forest, "acc")

# Calculate AUC
auc_random_forest <- performance(prediction_random_forest, measure = "auc")

# Append the results to the dataframe
results <- bind_rows(
  results,
  data_frame(
    Algorithm = "#4 - Random Forest",
    TP = random_forest_confusion_matrix$table[1,1],
    TN = random_forest_confusion_matrix$table[2,2],
    FP = random_forest_confusion_matrix$table[2,1],
    FN = random_forest_confusion_matrix$table[1,2],
    Accuracy = random_forest_confusion_matrix$overall["Accuracy"],
    Sensitivity = random_forest_confusion_matrix$byClass["Sensitivity"],
    FPR = 1 - random_forest_confusion_matrix$byClass["Specificity"],
    Specificity = random_forest_confusion_matrix$byClass["Specificity"],
    AUC = as.numeric(auc_random_forest@y.values),
    Time = time_random_forest)
)

```

The confusion matrix for this algorithm is:

```{r confusion-matrix-random-forest, warning = FALSE, message = TRUE}
random_forest_confusion_matrix$table
```

The performance of this algorithm is:

* **True Positive**: `r random_forest_confusion_matrix$table[1,1]`
* **True Negative**: `r random_forest_confusion_matrix$table[2,2]`
* **False Positive**: `r random_forest_confusion_matrix$table[2,1]`
* **False Negative**: `r random_forest_confusion_matrix$table[1,2]`
* **Accuracy**: `r random_forest_confusion_matrix$overall["Accuracy"]`
* **True Positive Rate - Sensitivity**: `r random_forest_confusion_matrix$byClass["Sensitivity"]`
* **False Positive Rate**: `r 1 - random_forest_confusion_matrix$byClass["Specificity"]`
* **Specificity**: `r random_forest_confusion_matrix$byClass["Specificity"]`
* **AUC**: `r as.numeric(auc_random_forest@y.values)`
* **Time to be executed**: `r time_random_forest` seconds

The ROC curve of this algorithm is

```{r roc-random_forest, echo = FALSE, warning = FALSE, message = FALSE, fig.cap="ROC for Random Forest"}

plot.new()
roc_random_forest <- performance(prediction_random_forest,"tpr","fpr")
plot(roc_random_forest, colorize = T, lwd = 2)
abline(a = 0, b = 1) 
title(main = "ROC - Random Forest")

```

`\newpage{}`{=latex}'

### Resume

In the next table are indicated the algorithms´ performance metrics being **Random Forest** the one with the **best performance** followed by **Decision Tree**.

In the othe side, the algorithm with the **worst performance** is **Naive Bayes**.

The algorithm that takes more time to be executed is the one with the majority of the best performance metrics: **Random Forest**.

```{r table-results, warning = FALSE, message = FALSE}
options(digits = 4) 

results %>% kbl(.,
                booktabs = T, 
                caption = "Results obtained") %>% 
  kable_styling(latex_options = "HOLD_position") %>%
  row_spec(0, bold = T) %>% 
  column_spec(
    2, 
    color = "red",
    background = spec_color(
      results$TP, 
      direction= 1,
      end=1.0),
    popover = paste("TP", results$TP)) %>% 
  column_spec(
    3, 
    color = "red",
    background = spec_color(
      results$TN, 
      direction= 1,
      end=1.0),
    popover = paste("TN:", results$TN)) %>% 
  column_spec(
    4, 
    color = "red",
    background = spec_color(
      results$FP, 
      direction= -1,
      end=1.0),
    popover = paste("FP:", results$FP)) %>% 
  column_spec(
    5, 
    color = "red",
    background = spec_color(
      results$FN, 
      direction= -1,
      end=1.0),
    popover = paste("FN:", results$FN)) %>%
  column_spec(
    6, 
    color = "red",
    background = spec_color(
      results$Accuracy, 
      direction= 1,
      end=1.0),
    popover = paste("Accuracy:", results$Accuracy)) %>% 
  column_spec(
    7, 
    color = "red",
    background = spec_color(
      results$Sensitivity, 
      direction= 1,
      end=1.0),
    popover = paste("Sensitivity:", results$Sensitivity)) %>% 
  column_spec(
    8, 
    color = "red",
    background = spec_color(
      results$FPR, 
      direction= -1,
      end=1.0),
    popover = paste("FPR:", results$FPR)) %>% 
  column_spec(
    9, 
    color = "red",
    background = spec_color(
      results$Specificity, 
      direction= 1,
      end=1.0),
    popover = paste("Specificity:", results$Specificity)) %>%
  column_spec(
    10, 
    color = "red",
    background = spec_color(
      results$AUC, 
      direction= 1,
      end=1.0),
    popover = paste("AUC:", results$AUC)) %>%
  column_spec(
    11, 
    color = "red",
    background = spec_color(
      results$Time, 
      direction= -1,
      end=1.0),
    popover = paste("Time:", results$Time))

```

`\newpage{}`{=latex}'

# Conclusion

The algorithm that classify the files with the highest **accurary** (**`r round(random_forest_confusion_matrix$overall["Accuracy"],4)`**) is **Random Forest**, this algorithm is the one that takes more time to run: **`r time_random_forest`** seconds. The second best algorithm is **Decision Tree** (with an accuracy of **0.9752**) that takes **`r time_tree`** seconds to be executed.

About **sensitivity**, **Decision Tree** has the highest ratio (**0.9943**) with **9,622** files identified as **malware**, there is a difference with respect to **Random Forest** with a ratio of **`r round(random_forest_confusion_matrix$byClass["Sensitivity"],4)`** and **`r format(random_forest_confusion_matrix$table[1,1], big.mark=",")`** files identified as **malware**, which is good because with this techniques, the technological infrastructure can be protected against a cyberattack.

For **specificity**, **Random Forest** has the highest ratio (**`r round(random_forest_confusion_matrix$byClass["Specificity"],4)`**) with **`r format(random_forest_confusion_matrix$table[2,2], big.mark=",")`** files identified as **not malware**, there is a difference with respect to **Decision Tree** with a ratio of **0.9302** and **3,840** files identified as **not malware**.

An issue can be presented when a file **without malware** is classified as **malware**, in this case **Random Forest** is the best option with a ratio of **`r round(1 - random_forest_confusion_matrix$byClass["Specificity"],4)`** with **`r format(random_forest_confusion_matrix$table[2,1], big.mark=",")`** files in this situation.

As an improvement **kNN algorithm** can be used, for this project an end-user device with **8 GiB RAM, 2 virtual cores, 2.90 GHz Intel processor speed running Windows 10 was used** and at the moment to run the following error message was generated: **"Error: cannot allocate vector of size 12.8 Gb"**.

Also techniques more advanced such as **neural networks** and **deep learning** can be explored as a way to increase the accuracy of the classification.

`\newpage{}`{=latex}'

# Appendix A - PE file fields structure

```{r table-pe_file-characteristics, warning = FALSE, message = TRUE}

Name_field <- paste("Name of the application running. Some values obtained from the dataset are: ",data_loaded$Name[1],", ",data_loaded$Name[40979],", ",data_loaded$Name[max(nrow(data_loaded))],", ",data_loaded$Name[max(nrow(data_loaded))-1000],".",sep="")

md5_field <- paste("Unique MD5 (Message-Digest algorithm 5) hash generated to every process running. Some values obtained from the dataset are: ",data_loaded$md5[1],", ",data_loaded$md5[1000],", ",data_loaded$md5[max(nrow(data_loaded))],", ",data_loaded$md5[max(nrow(data_loaded))-1000],".",sep="")

Machine_field <- coff_file_header$Description[1] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+")
Machine_field <- paste(Machine_field,"."," Some values obtained from the dataset are: ",data_loaded$Machine[1],", ",data_loaded$Machine[21090],", ",data_loaded$Machine[35072],".",sep="")

SizeOfOptionalHeader_field <- coff_file_header$Description[6] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+,[[\\w+]+[\\s+]+]+.[[\\w+]+[\\s+]+]+")
SizeOfOptionalHeader_field <- paste(SizeOfOptionalHeader_field,"."," Some values obtained from the dataset are: ",data_loaded$SizeOfOptionalHeader[1],", ",data_loaded$SizeOfOptionalHeader[14234],", ",data_loaded$SizeOfOptionalHeader[72682],", ",data_loaded$SizeOfOptionalHeader[106612],".",sep="")

Characteristics_field <- coff_file_header$Description[7] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+")
Characteristics_field <- paste(Characteristics_field,"."," Some values obtained from the dataset are: ",data_loaded$Characteristics[9112],", ",data_loaded$Characteristics[108566],", ",data_loaded$Characteristics[8029],", ",data_loaded$Characteristics[56812],".",sep="")

MajorLinkerVersion_field <- optional_header_standard_fields$Description[2] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+")
MajorLinkerVersion_field <- paste(MajorLinkerVersion_field,"."," Some values obtained from the dataset are: ",data_loaded$MajorLinkerVersion[43393],", ",data_loaded$MajorLinkerVersion[57211],", ",data_loaded$MajorLinkerVersion[91463],", ",data_loaded$MajorLinkerVersion[135049],".",sep="")

MinorLinkerVersion_field <- optional_header_standard_fields$Description[3] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+")
MinorLinkerVersion_field <- paste(MinorLinkerVersion_field,"."," Some values obtained from the dataset are: ",data_loaded$MinorLinkerVersion[73200],", ",data_loaded$MinorLinkerVersion[131727],", ",data_loaded$MinorLinkerVersion[80078],", ",data_loaded$MinorLinkerVersion[123185],".",sep="")

SizeOfCode_field <- optional_header_standard_fields$Description[4] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+\\([\\w+]+\\)[\\s+][\\w+]+,[[\\w+]+[\\s+]+]+")
SizeOfCode_field <- paste(SizeOfCode_field,"."," Some values obtained from the dataset are: ",data_loaded$SizeOfCode[131974],", ",data_loaded$SizeOfCode[102989],", ",data_loaded$SizeOfCode[104508],", ",data_loaded$SizeOfCode[62702],".",sep="")

SizeOfInitializedData_field <-  optional_header_standard_fields$Description[5] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+[\\w+]+[\\s+][\\w+]+,[[\\w+]+[\\s+]+]+")
SizeOfInitializedData_field <- paste(SizeOfInitializedData_field,"."," Some values obtained from the dataset are: ",data_loaded$SizeOfInitializedData[21363],", ",data_loaded$SizeOfInitializedData[110300],", ",data_loaded$SizeOfInitializedData[106931],", ",data_loaded$SizeOfInitializedData[137971],".",sep="")

SizeOfUninitializedData_field <-  optional_header_standard_fields$Description[6] %>% str_extract(., "^T[[\\w+]+[\\s+]+]+\\([\\w+]+\\),[\\s+][\\w+]+[[\\w+]+[\\s+]+]+")
SizeOfUninitializedData_field <- paste(SizeOfUninitializedData_field,"."," Some values obtained from the dataset are: ",data_loaded$SizeOfUninitializedData[80545],", ",data_loaded$SizeOfUninitializedData[88018],", ",data_loaded$SizeOfUninitializedData[94921],", ",data_loaded$SizeOfUninitializedData[45599],".",sep="")

AddressOfEntryPoint_field <-  paste(optional_header_standard_fields$Description[7]," Some values obtained from the dataset are: ",data_loaded$AddressOfEntryPoint[6105],", ",data_loaded$AddressOfEntryPoint[113918],", ",data_loaded$AddressOfEntryPoint[36107],", ",data_loaded$AddressOfEntryPoint[71280],".",sep="")

BaseOfCode_field <-  paste(optional_header_standard_fields$Description[8]," Some values obtained from the dataset are: ",data_loaded$BaseOfCode[22414],", ",data_loaded$BaseOfCode[49443],", ",data_loaded$BaseOfCode[94919],", ",data_loaded$BaseOfCode[79044],".",sep="")

BaseOfData_field <- paste(pe32_additional_field$Description[1]," Some values obtained from the dataset are: ",data_loaded$BaseOfData[5505],", ",data_loaded$BaseOfData[87520],", ",data_loaded$BaseOfData[64579],", ",data_loaded$BaseOfData[137],".",sep="")

ImageBase_field <- paste(optional_header_windows_specific_fields$Description[1]," Some values obtained from the dataset are: ",data_loaded$ImageBase[13115],", ",data_loaded$ImageBase[114812],", ",data_loaded$ImageBase[22885],", ",data_loaded$ImageBase[35540],".",sep="")

SectionAlignment_field <- paste(optional_header_windows_specific_fields$Description[2]," Some values obtained from the dataset are: ",data_loaded$SectionAlignment[22705],", ",data_loaded$SectionAlignment[1103],", ",data_loaded$SectionAlignment[40464],", ",data_loaded$SectionAlignment[15699],".",sep="")

FileAlignment_field <- paste(optional_header_windows_specific_fields$Description[3]," Some values obtained from the dataset are: ",data_loaded$FileAlignment[238],", ",data_loaded$FileAlignment[22705],", ",data_loaded$FileAlignment[10611],", ",data_loaded$FileAlignment[7931],".",sep="")
  
MajorOperatingSystemVersion_field <- paste(optional_header_windows_specific_fields$Description[4]," Some values obtained from the dataset are: ",data_loaded$MajorOperatingSystemVersion[21130],", ",data_loaded$MajorOperatingSystemVersion[25311],", ",data_loaded$MajorOperatingSystemVersion[15819],", ",data_loaded$MajorOperatingSystemVersion[29329],".",sep="")

MinorOperatingSystemVersion_field <- paste(optional_header_windows_specific_fields$Description[5]," Some values obtained from the dataset are: ",data_loaded$MinorOperatingSystemVersion[115522],", ",data_loaded$MinorOperatingSystemVersion[70083],", ",data_loaded$MinorOperatingSystemVersion[27358],", ",data_loaded$MinorOperatingSystemVersion[132632],".",sep="")

MajorImageVersion_field <- paste(optional_header_windows_specific_fields$Description[6]," Some values obtained from the dataset are: ",data_loaded$MajorImageVersion[25982],", ",data_loaded$MajorImageVersion[1655],", ",data_loaded$MajorImageVersion[104656],", ",data_loaded$MajorImageVersion[108564],".",sep="")

MinorImageVersion_field <- paste(optional_header_windows_specific_fields$Description[7]," Some values obtained from the dataset are: ",data_loaded$MinorImageVersion[57395],", ",data_loaded$MinorImageVersion[29087],", ",data_loaded$MinorImageVersion[5351],", ",data_loaded$MinorImageVersion[40510],".",sep="")

MajorSubsystemVersion_field <- paste(optional_header_windows_specific_fields$Description[8]," Some values obtained from the dataset are: ",data_loaded$MajorSubsystemVersion[133527],", ",data_loaded$MajorSubsystemVersion[98341],", ",data_loaded$MajorSubsystemVersion[315],", ",data_loaded$MajorSubsystemVersion[30863],".",sep="")

MinorSubsystemVersion_field <- paste(optional_header_windows_specific_fields$Description[9]," Some values obtained from the dataset are: ",data_loaded$MinorSubsystemVersion[118879],", ",data_loaded$MinorSubsystemVersion[25076],", ",data_loaded$MinorSubsystemVersion[118309],", ",data_loaded$MinorSubsystemVersion[116334],".",sep="")

SizeOfImage_field <- paste(optional_header_windows_specific_fields$Description[11]," Some values obtained from the dataset are: ",data_loaded$SizeOfImage[23285],", ",data_loaded$SizeOfImage[130076],", ",data_loaded$SizeOfImage[35904],", ",data_loaded$SizeOfImage[96613],".",sep="")

SizeOfHeaders_field <- paste(optional_header_windows_specific_fields$Description[12]," Some values obtained from the dataset are: ",data_loaded$SizeOfHeaders[78674],", ",data_loaded$SizeOfHeaders[127276],", ",data_loaded$SizeOfHeaders[109971],", ",data_loaded$SizeOfHeaders[37333],".",sep="")

CheckSum_field <- paste(optional_header_windows_specific_fields$Description[13]," Some values obtained from the dataset are: ",data_loaded$CheckSum[134282],", ",data_loaded$CheckSum[1295],", ",data_loaded$CheckSum[92828],", ",data_loaded$CheckSum[57600],".",sep="")

Subsystem_field <- paste(optional_header_windows_specific_fields$Description[14]," Some values obtained from the dataset are: ",data_loaded$Subsystem[22288],", ",data_loaded$Subsystem[77292],", ",data_loaded$Subsystem[1371],", ",data_loaded$Subsystem[8343],".",sep="")
  
DllCharacteristics_field <- paste("This field has the following descriptions: ", dll_characteristics_fields$Description[5], " ", dll_characteristics_fields$Description[6]," ", dll_characteristics_fields$Description[7]," ", dll_characteristics_fields$Description[8]," ", dll_characteristics_fields$Description[9]," ", dll_characteristics_fields$Description[10]," ", dll_characteristics_fields$Description[11]," ", dll_characteristics_fields$Description[12]," ", dll_characteristics_fields$Description[13]," ", dll_characteristics_fields$Description[14]," ", dll_characteristics_fields$Description[15]," Some values obtained from the dataset are: ",data_loaded$DllCharacteristics[29065],", ",data_loaded$DllCharacteristics[112916],", ",data_loaded$DllCharacteristics[98308],", ",data_loaded$DllCharacteristics[26811],".",sep="")

SizeOfStackReserve_field <- paste(optional_header_windows_specific_fields$Description[16]," Some values obtained from the dataset are: ",data_loaded$SizeOfStackReserve[11987],", ",data_loaded$SizeOfStackReserve[51311],", ",data_loaded$SizeOfStackReserve[25850],", ",data_loaded$SizeOfStackReserve[46645],".",sep="")

SizeOfStackCommit_field <- paste(optional_header_windows_specific_fields$Description[17]," Some values obtained from the dataset are: ",data_loaded$SizeOfStackCommit[36046],", ",data_loaded$SizeOfStackCommit[76414],", ",data_loaded$SizeOfStackCommit[311],", ",data_loaded$SizeOfStackCommit[737],".",sep="")

SizeOfHeapReserve_field <- paste(optional_header_windows_specific_fields$Description[18]," Some values obtained from the dataset are: ",data_loaded$SizeOfHeapReserve[30099],", ",data_loaded$SizeOfHeapReserve[1357],", ",data_loaded$SizeOfHeapReserve[83067],", ",data_loaded$SizeOfHeapReserve[135155],".",sep="")

SizeOfHeapCommit_field <- paste(optional_header_windows_specific_fields$Description[19]," Some values obtained from the dataset are: ",data_loaded$SizeOfHeapCommit[4357],", ",data_loaded$SizeOfHeapCommit[25851],", ",data_loaded$SizeOfHeapCommit[20937],", ",data_loaded$SizeOfHeapCommit[50060],".",sep="")

LoaderFlags_field <- paste(optional_header_windows_specific_fields$Description[20]," Some values obtained from the dataset are: ",data_loaded$LoaderFlags[107962],", ",data_loaded$LoaderFlags[112859],", ",data_loaded$LoaderFlags[79716],", ",data_loaded$LoaderFlags[116334],".",sep="")

NumberOfRvaAndSizes_field <- paste(optional_header_windows_specific_fields$Description[21]," Some values obtained from the dataset are: ",data_loaded$NumberOfRvaAndSizes[19216],", ",data_loaded$NumberOfRvaAndSizes[120011],", ",data_loaded$NumberOfRvaAndSizes[126236],", ",data_loaded$NumberOfRvaAndSizes[72049],".",sep="")

SectionsNb_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$SectionsNb[45893],", ",data_loaded$SectionsNb[16920],", ",data_loaded$SectionsNb[99243],", ",data_loaded$SectionsNb[128678],".",sep="")

SectionsMeanEntropy_field <- paste("Mean entropy of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionsMeanEntropy[57729],", ",data_loaded$SectionsMeanEntropy[108313],", ",data_loaded$SectionsMeanEntropy[4387],", ",data_loaded$SectionsMeanEntropy[111353],".",sep="")

SectionsMinEntropy_field <- paste("Minimal entropy of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionsMinEntropy[21313],", ",data_loaded$SectionsMinEntropy[98359],", ",data_loaded$SectionsMinEntropy[134017],", ",data_loaded$SectionsMinEntropy[79436],".",sep="")

SectionsMaxEntropy_field <- paste("Maximum entropy of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionsMaxEntropy[4845],", ",data_loaded$SectionsMaxEntropy[19293],", ",data_loaded$SectionsMaxEntropy[2784],", ",data_loaded$SectionsMaxEntropy[41577],".",sep="")

SectionsMeanRawsize_field <- paste("Mean raw size of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionsMeanRawsize[24946],", ",data_loaded$SectionsMeanRawsize[88610],", ",data_loaded$SectionsMeanRawsize[129655],", ",data_loaded$SectionsMeanRawsize[120489],".",sep="")

SectionsMinRawsize_field <- paste("Minimal raw size of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionsMinRawsize[157],", ",data_loaded$SectionsMinRawsize[56005],", ",data_loaded$SectionsMinRawsize[84920],", ",data_loaded$SectionsMinRawsize[135453],".",sep="")

SectionMaxRawsize_field <- paste("Maximum raw size of the file sections." ," Some values obtained from the dataset are: ",data_loaded$SectionMaxRawsize[19290],", ",data_loaded$SectionMaxRawsize[35015],", ",data_loaded$SectionMaxRawsize[55912],", ",data_loaded$SectionMaxRawsize[25778],".",sep="")

SectionsMeanVirtualsize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$SectionsMeanVirtualsize[2567],", ",data_loaded$SectionsMeanVirtualsize[40190],", ",data_loaded$SectionsMeanVirtualsize[130860],", ",data_loaded$SectionsMeanVirtualsize[95661],".",sep="")

SectionsMinVirtualsize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$SectionsMinVirtualsize[8016],", ",data_loaded$SectionsMinVirtualsize[24140],", ",data_loaded$SectionsMinVirtualsize[105482],", ",data_loaded$SectionsMinVirtualsize[36395],".",sep="")

SectionMaxVirtualsize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$SectionMaxVirtualsize[98503],", ",data_loaded$SectionMaxVirtualsize[112300],", ",data_loaded$SectionMaxVirtualsize[31943],", ",data_loaded$SectionMaxVirtualsize[72584],".",sep="")

ImportsNbDLL_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ImportsNbDLL[30543],", ",data_loaded$ImportsNbDLL[78380],", ",data_loaded$ImportsNbDLL[35977],", ",data_loaded$ImportsNbDLL[29443],".",sep="")

ImportsNb_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ImportsNb[76237],", ",data_loaded$ImportsNb[20623],", ",data_loaded$ImportsNb[17960],", ",data_loaded$ImportsNb[37185],".",sep="")

ImportsNbOrdinal_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ImportsNbOrdinal[45765],", ",data_loaded$ImportsNbOrdinal[8779],", ",data_loaded$ImportsNbOrdinal[30286],", ",data_loaded$ImportsNbOrdinal[25502],".",sep="")

ExportNb_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ExportNb[3784],", ",data_loaded$ExportNb[987],", ",data_loaded$ExportNb[26752],", ",data_loaded$ExportNb[14900],".",sep="")

ResourcesNb_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesNb[6562],", ",data_loaded$ResourcesNb[76014],", ",data_loaded$ResourcesNb[3912],", ",data_loaded$ResourcesNb[21907],".",sep="")

ResourcesMeanEntropy_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMeanEntropy[20513],", ",data_loaded$ResourcesMeanEntropy[71621],", ",data_loaded$ResourcesMeanEntropy[134717],", ",data_loaded$ResourcesMeanEntropy[135181],".",sep="")

ResourcesMinEntropy_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMinEntropy[14951],", ",data_loaded$ResourcesMinEntropy[63781],", ",data_loaded$ResourcesMinEntropy[88540],", ",data_loaded$ResourcesMinEntropy[61591],".",sep="")

ResourcesMaxEntropy_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMaxEntropy[7841],", ",data_loaded$ResourcesMaxEntropy[118399],", ",data_loaded$ResourcesMaxEntropy[38201],", ",data_loaded$ResourcesMaxEntropy[111359],".",sep="")

ResourcesMeanSize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMeanSize[25269],", ",data_loaded$ResourcesMeanSize[82224],", ",data_loaded$ResourcesMeanSize[58835],", ",data_loaded$ResourcesMeanSize[1829],".",sep="")

ResourcesMinSize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMinSize[80485],", ",data_loaded$ResourcesMinSize[81495],", ",data_loaded$ResourcesMinSize[29363],", ",data_loaded$ResourcesMinSize[6014],".",sep="")

ResourcesMaxSize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$ResourcesMaxSize[35129],", ",data_loaded$ResourcesMaxSize[81463],", ",data_loaded$ResourcesMaxSize[56979],", ",data_loaded$ResourcesMaxSize[16023],".",sep="")

LoadConfigurationSize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$LoadConfigurationSize[3726],", ",data_loaded$LoadConfigurationSize[38613],", ",data_loaded$LoadConfigurationSize[35431],", ",data_loaded$LoadConfigurationSize[112112],".",sep="")

VersionInformationSize_field <- paste("No information found about this field." ," Some values obtained from the dataset are: ",data_loaded$VersionInformationSize[47323],", ",data_loaded$VersionInformationSize[85011],", ",data_loaded$VersionInformationSize[100471],", ",data_loaded$VersionInformationSize[16453],".",sep="")

legitimate_field <- "If a \"0\" appears indicate that the file is a malware and if a \"1\" appears indicate that the file is not a malware."

tribble(
  ~"Column name", ~"Type", ~"Description",
  "Name", 
  class(data_loaded$Name),Name_field,
  "md5", 
  class(data_loaded$md5),md5_field,
  "Machine", 
  class(data_loaded$Machine),Machine_field,
  "SizeOfOptionalHeader", 
  class(data_loaded$SizeOfOptionalHeader),SizeOfOptionalHeader_field,
  "Characteristics", 
  class(data_loaded$Characteristics),Characteristics_field,
  "MajorLinkerVersion", 
  class(data_loaded$MajorLinkerVersion),MajorLinkerVersion_field,
  "MinorLinkerVersion", 
  class(data_loaded$MinorLinkerVersion),MinorLinkerVersion_field,
  "SizeOfCode", 
  class(data_loaded$SizeOfCode),SizeOfCode_field,
  "SizeOfInitializedData", 
  class(data_loaded$SizeOfInitializedData),SizeOfInitializedData_field,
  "SizeOfUninitializedData", 
  class(data_loaded$SizeOfUninitializedData),SizeOfUninitializedData_field,
  "AddressOfEntryPoint", 
  class(data_loaded$AddressOfEntryPoint),AddressOfEntryPoint_field,
  "BaseOfCode", 
  class(data_loaded$BaseOfCode),BaseOfCode_field,
  "BaseOfData", 
  class(data_loaded$BaseOfData),BaseOfData_field,
  "ImageBase", 
  class(data_loaded$ImageBase),ImageBase_field,
  "SectionAlignment", 
  class(data_loaded$SectionAlignment),SectionAlignment_field,
  "FileAlignment", 
  class(data_loaded$FileAlignment),FileAlignment_field,
  "MajorOperatingSystemVersion", 
  class(data_loaded$MajorOperatingSystemVersion),MajorOperatingSystemVersion_field,
  "MinorOperatingSystemVersion", 
  class(data_loaded$MinorOperatingSystemVersion),MinorOperatingSystemVersion_field,
  "MajorImageVersion", 
  class(data_loaded$MajorImageVersion),MajorImageVersion_field,
  "MinorImageVersion", 
  class(data_loaded$MinorImageVersion),MinorImageVersion_field,
  "MajorSubsystemVersion", 
  class(data_loaded$MajorSubsystemVersion),MajorSubsystemVersion_field,
  "MinorSubsystemVersion", 
  class(data_loaded$MinorSubsystemVersion),MinorSubsystemVersion_field,
  "SizeOfImage", 
  class(data_loaded$SizeOfImage),SizeOfImage_field,
  "SizeOfHeaders", 
  class(data_loaded$SizeOfHeaders),SizeOfHeaders_field,
  "CheckSum", 
  class(data_loaded$CheckSum),CheckSum_field,
  "Subsystem", 
  class(data_loaded$Subsystem),Subsystem_field,
  "DllCharacteristics", 
  class(data_loaded$DllCharacteristics),DllCharacteristics_field,
  "SizeOfStackReserve", 
  class(data_loaded$SizeOfStackReserve),SizeOfStackReserve_field,
  "SizeOfStackCommit", 
  class(data_loaded$SizeOfStackCommit),SizeOfStackCommit_field,
  "SizeOfHeapReserve", 
  class(data_loaded$SizeOfHeapReserve),SizeOfHeapReserve_field,
  "SizeOfHeapCommit", 
  class(data_loaded$SizeOfHeapCommit),SizeOfHeapCommit_field,
  "LoaderFlags", 
  class(data_loaded$LoaderFlags),LoaderFlags_field,
  "NumberOfRvaAndSizes", 
  class(data_loaded$NumberOfRvaAndSizes),NumberOfRvaAndSizes_field,
  "SectionsNb", 
  class(data_loaded$SectionsNb),SectionsNb_field,
  "SectionsMeanEntropy", 
  class(data_loaded$SectionsMeanEntropy),SectionsMeanEntropy_field,
  "SectionsMinEntropy", 
  class(data_loaded$SectionsMinEntropy),SectionsMinEntropy_field,
  "SectionsMaxEntropy", 
  class(data_loaded$SectionsMaxEntropy),SectionsMaxEntropy_field,
  "SectionsMeanRawsize", 
  class(data_loaded$SectionsMeanRawsize),SectionsMeanRawsize_field,
  "SectionsMinRawsize", 
  class(data_loaded$SectionsMinRawsize),SectionsMinRawsize_field,
  "SectionMaxRawsize", 
  class(data_loaded$SectionMaxRawsize),SectionMaxRawsize_field,
  "SectionsMeanVirtualsize", 
  class(data_loaded$SectionsMeanVirtualsize),SectionsMeanVirtualsize_field,
  "SectionsMinVirtualsize", 
  class(data_loaded$SectionsMinVirtualsize),SectionsMinVirtualsize_field,
  "SectionMaxVirtualsize", 
  class(data_loaded$SectionMaxVirtualsize),SectionMaxVirtualsize_field,
  "ImportsNbDLL", 
  class(data_loaded$ImportsNbDLL),ImportsNbDLL_field,
  "ImportsNb", 
  class(data_loaded$ImportsNb),ImportsNb_field,
  "ImportsNbOrdinal", 
  class(data_loaded$ImportsNbOrdinal),ImportsNbOrdinal_field,
  "ExportNb", 
  class(data_loaded$ExportNb),ExportNb_field,
  "ResourcesNb", 
  class(data_loaded$ResourcesNb),ResourcesNb_field,
  "ResourcesMeanEntropy", 
  class(data_loaded$ResourcesMeanEntropy),ResourcesMeanEntropy_field,
  "ResourcesMinEntropy", 
  class(data_loaded$ResourcesMinEntropy),ResourcesMinEntropy_field,
  "ResourcesMaxEntropy", 
  class(data_loaded$ResourcesMaxEntropy),ResourcesMaxEntropy_field,
  "ResourcesMeanSize", 
  class(data_loaded$ResourcesMeanSize),ResourcesMeanSize_field,
  "ResourcesMinSize", 
  class(data_loaded$ResourcesMinSize),ResourcesMinSize_field,
  "ResourcesMaxSize", 
  class(data_loaded$ResourcesMaxSize),ResourcesMaxSize_field,
  "LoadConfigurationSize", 
  class(data_loaded$LoadConfigurationSize),LoadConfigurationSize_field,
  "VersionInformationSize", 
  class(data_loaded$VersionInformationSize),VersionInformationSize_field,
  "legitimate",
  class(data_loaded$legitimate),legitimate_field) %>% 
  kbl(., booktabs = T, longtable= T, caption = "PE file structure fields description") %>% kable_styling(latex_options = c("HOLD_position","repeat_header")) %>% row_spec(0, bold = T) %>% column_spec(1, bold = T, color = "blue") %>% column_spec(2, bold = T) %>% column_spec(3, width = "30em")

```

`\newpage{}`{=latex}'


# References
* Introduction to Data Science. Rafael A. Irizarry. https://rafalab.github.io/dsbook/
* Create Awesome LaTeX Table with knitr::kable and kableExtra. Hao Zhu. https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_pdf.pdf
* R Markdown Cookbook. https://bookdown.org/yihui/rmarkdown-cookbook/
* What is a malware?. https://www.cisco.com/c/en/us/products/security/advanced-malware-protection/what-is-malware.html
* 2022 Cyber Attack Statistics, Data, and Trends. https://parachute.cloud/2022-cyber-attack-statistics-data-and-trends/
* Malware statistics and facts for 2022. https://www.comparitech.com/antivirus/malware-statistics-facts/
* 2021 Cyber Security Statistics The Ultimate List Of Stats, Data & Trends. https://purplesec.us/resources/cyber-security-statistics/
* Cybercrime To Cost The World $10.5 Trillion Annually By 2025. https://cybersecurityventures.com/cybercrime-damages-6-trillion-by-2021/
* How to use Kaggle API to download datasets in R. https://medium.com/mcd-unison/how-to-use-kaggle-api-to-download-datasets-in-r-312179c7a99c
* A Comprehensive Guide To PE Structure, The Layman’s Way. https://tech-zealots.com/malware-analysis/pe-portable-executable-structure-malware-analysis-part-2/
* PE Format. https://docs.microsoft.com/en-us/windows/win32/debug/pe-format
* Malware researcher’s handbook (demystifying PE file). https://resources.infosecinstitute.com/topic/2-malware-researchers-handbook-demystifying-pe-file/
* Detailed analysis of PE file format. https://programmer.ink/think/detailed-analysis-of-pe-file-format.html
* File Entropy – Let’s talk about Randomness (Malware Analysis – Chapter 2). https://www.talentcookie.com/2016/02/05/file-entropy-in-malware-analysis/
* Decoding the Confusion Matrix. https://towardsdatascience.com/decoding-the-confusion-matrix-bb4801decbb
* Logistic regression. https://en.wikipedia.org/wiki/Logistic_regression
* Naive Bayes classifier. https://en.wikipedia.org/wiki/Naive_Bayes_classifier
* Decision tree learning. https://en.wikipedia.org/wiki/Decision_tree_learning
* Random Forest. https://en.wikipedia.org/wiki/Random_forest
* R Random Forest – Ensemble Learning Methods in R. https://techvidvan.com/tutorials/r-random-forest/

[cisco]: https://www.cisco.com/c/en_au/about/who-is-head.html
[malware]: https://www.cisco.com/c/en/us/products/security/advanced-malware-protection/what-is-malware.html
[mimecast]: https://www.mimecast.com/globalassets/documents/ebook/state-of-email-security-report-2021.pdf
[kaggle_dataset]: https://www.kaggle.com/divg07/malware-analysis-dataset
[PE_format]: https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Portable_Executable_32_bit_Structure_in_SVG_fixed.svg/849px-Portable_Executable_32_bit_Structure_in_SVG_fixed.svg.png
[pdf_file]: https://github.com/HugoAquinoNavarrete/Malware/blob/main/Malware.pdf
[rmd_file]: https://github.com/HugoAquinoNavarrete/Malware/blob/main/Malware.rmd
[r_file]: https://github.com/HugoAquinoNavarrete/Malware/blob/main/Malware.R
[github]: https://github.com/HugoAquinoNavarrete/Malware